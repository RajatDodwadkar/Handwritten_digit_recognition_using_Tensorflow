{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZpztRwBouwYp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd() \n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
    "\n",
    "# Get only training set\n",
    "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path=data_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_normalize(images):\n",
    "    img =[]\n",
    "    for image in images:\n",
    "        # Reshape the images to add an extra dimension\n",
    "        img.append(np.resize(image,(28,28,1)))\n",
    "    images=np.array(img)\n",
    "    # Normalize pixel values\n",
    "    images = images / 255.0\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path=data_path) \n",
    "\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "    # Check accuracy\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    model = tf.keras.models.Sequential([ \n",
    "      tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ]) \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.1440 - accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0487 - accuracy: 0.9848\n",
      "Epoch 3/10\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9900\n",
      "Reached 99% accuracy so cancelling training!\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0307 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "model = convolutional_model()\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "history = model.fit(training_images, training_labels, epochs=10,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 74.4980 - accuracy: 0.9066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[74.49800872802734, 0.9065999984741211]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(test_images)\n",
    "print(pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP3UlEQVR4nO3deaxc9XnG8e9jY0zYGhywsY3BBNzUCCkmunabGFpSxNqmJqgQaAuOROu0BaVIqIFSKVhp1DpVSQQioTVLMGUrKSCciLSAG0pRE8M1NWDjhtWAsbExqyHg9e0fc5yO4c6Z69nO2O/zkUYzc37nnN97R/e5Z537U0RgZru/EVUXYGa94bCbJeGwmyXhsJsl4bCbJeGwmyXhsNsvSZor6eaq67DucNj7iKQHJb0pafQw5/+ypIe7XVfR1/GSVvWiL+sOh71PSJoMHAcE8HuVFmO7JYe9f5wH/Ay4EZhd3yBpkqS7JL0m6XVJV0uaCvwj8FlJ70p6q5j3QUl/XLfsDlt/SVdKelnSO5KWSDqulWKLfr4p6b+L/n8o6ROSbinW/WjxB6xpv5I+JmlBsVezQtLX6vciJE2QdGfx878g6aut1Jydw94/zgNuKR4nSxoHIGkk8CPgRWAyMBG4PSJWAH8K/DQi9o2Ijw+zn0eBacAY4FbgB5L2arHms4Fzi5qOAH4KfL9Y9wrg8mH2e3nxs30SOBH4o+0LSRoB/BB4vOjnBOAiSSe3WHNaDnsfkHQscBhwR0QsAZ4D/qBongFMAP4yIt6LiA8iouXj9Ii4OSJej4gtEXEFMBr4VIur+35EPBcRbwM/Bp6LiAciYgvwA+CYYfZ7FvC3EfFmRKwCrqrrYzpwUER8IyI2RcTzwLXU/tDYTnDY+8Ns4L6IWF+8v5X/35WfBLxYBKhtki4udpXfLnb9fwU4sMXVra17/f4Q7/cdZr8TgJfrlq1/fRgwQdJb2x/AZcC4FmtOa4+qC8hO0seobdlGSnq1mDwa+LikT1P7xT9U0h5DBH6oryy+B+xd9/7gur6OAy6htiu8PCK2SXoTUGd+mqENo981wCHAU8X7SXWLvwy8EBFTulljBt6yV+90YCtwFLVj2mnAVOC/qB3HP0ItDPMk7SNpL0kzi2XXAodI2rNufUuBMyTtLelI4Py6tv2ALcBrwB6Svg7s370fbdj93gH8laQDJE0ELqxrewR4R9IlxYm8kZKOljS9B3XvVhz26s2mduz7UkS8uv0BXA38IbWt3xeAI4GXgFXAl4pl/wNYDrwqafshwHeATdT+ECygdsJvu3+ndmz9NLUTfh+w4y5ztzTr9xvUfq4XgAeAfwU2AkTEVmo//7SifT1wHbXDANsJ8j+vsH4j6c+AsyPit6quZXfiLbtVTtJ4STMljZD0KeBi4O6q69rd+ASd9YM9gX8CDgfeAm4HvldpRbsh78abJeHdeLMkerobv6dGx17s08suzVL5gPfYFBuHvG+irbBLOgW4EhgJXBcR88rm34t9+HWd0E6XZlZicSxq2NbybnzxBY3vAqdSuyHkHElHtbo+M+uudo7ZZwDPRsTzEbGJ2hnUWZ0py8w6rZ2wT2THu6BWFdN2IGmOpEFJg5trN0WZWQXaCftQJwE+ch0vIuZHxEBEDIxiWP9tycy6oJ2wr2LHbycdAqxurxwz65Z2wv4oMEXS4cW3rs4GFnamLDPrtJYvvUXEFkkXUvtG00jghohY3rHKzKyj2rrOHhH3Avd2qBYz6yLfLmuWhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNulkRbo7iaNfPWeZ9t2LZ43jWlyx713T8vbT/0W4+UtseWLaXt2bQVdkkrgQ3AVmBLRAx0oigz67xObNk/HxHrO7AeM+siH7ObJdFu2AO4T9ISSXOGmkHSHEmDkgY3s7HN7sysVe3uxs+MiNWSxgL3S/rfiHiofoaImA/MB9hfY6LN/sysRW1t2SNidfG8DrgbmNGJosys81oOu6R9JO23/TVwErCsU4WZWWe1sxs/Drhb0vb13BoR/9aRqmyXscfECaXtf/P161pe91MXfK+0/dSrjittjw0bWu57d9Ry2CPieeDTHazFzLrIl97MknDYzZJw2M2ScNjNknDYzZLwV1ytLetOPqy0/aS9N7e87s8Mfqm0/aB3n2553Rl5y26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhK+zW6kRe+9d2n7yVx/uWt+jbz+gfIbwPz7aGd6ymyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXh6+xWauPnppa2f3Ps9S2v+xfbNpW273/rz1pet32Ut+xmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSfg6u5V64YyRXVv37z9zepM5Vnet74yabtkl3SBpnaRlddPGSLpf0jPFc5P/MmBmVRvObvyNwCkfmnYpsCgipgCLivdm1seahj0iHgLe+NDkWcCC4vUCoNn+mJlVrNUTdOMiYg1A8Ty20YyS5kgalDS4mY0tdmdm7er62fiImB8RAxExMIrR3e7OzBpoNexrJY0HKJ7Xda4kM+uGVsO+EJhdvJ4N3NOZcsysW5peZ5d0G3A8cKCkVcDlwDzgDknnAy8BZ3azSKvO70x/vK3l3972fsO2zXPHlS47wtfZO6pp2CPinAZNJ3S4FjPrIt8ua5aEw26WhMNuloTDbpaEw26WhL/imtzG06aXtl898dq21r9qS+O2Ef/5P22t23aOt+xmSTjsZkk47GZJOOxmSTjsZkk47GZJOOxmSfg6e3Jrp4/q6vq/8KOLGrZNYXFX+7YdectuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloSvsye35zFvtrX8ik2/KG3/tavWN2zb2lbPtrO8ZTdLwmE3S8JhN0vCYTdLwmE3S8JhN0vCYTdLwtfZd3Mf/O6M0vbB6dc0WcPI0tafbx5b2r716eearN96pemWXdINktZJWlY3ba6kVyQtLR6ndbdMM2vXcHbjbwROGWL6dyJiWvG4t7NlmVmnNQ17RDwEvNGDWsysi9o5QXehpCeK3fwDGs0kaY6kQUmDm9nYRndm1o5Ww34NcAQwDVgDXNFoxoiYHxEDETEwitEtdmdm7Wop7BGxNiK2RsQ24Fqg/JSvmVWupbBLGl/39ovAskbzmll/aHqdXdJtwPHAgZJWAZcDx0uaBgSwEvhKF2u0Nrx/YPl18lEqb2/ma0vOKG0/nCfaWr91TtOwR8Q5Q0y+vgu1mFkX+XZZsyQcdrMkHHazJBx2syQcdrMk/BXX3dzG099qa/lm/yr6kOu6O+SzdY637GZJOOxmSTjsZkk47GZJOOxmSTjsZkk47GZJ+Dr7bmDkrx7RsG1w+s3Nli5t/fG7R5e2j3pgSZP1W7/wlt0sCYfdLAmH3SwJh90sCYfdLAmH3SwJh90sCV9n3w2s/XzjYZPb/VfRV//kxNL2KSxua/3WO96ymyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyUxnCGbJwE3AQcD24D5EXGlpDHAvwCTqQ3bfFZEvNm9Uq2RD8ao5WWXbNxU2j71W6tK27e03LP12nC27FuAiyNiKvAbwAWSjgIuBRZFxBRgUfHezPpU07BHxJqIeKx4vQFYAUwEZgELitkWAKd3q0gza99OHbNLmgwcAywGxkXEGqj9QQAa37NpZpUbdtgl7QvcCVwUEe/sxHJzJA1KGtzMxlZqNLMOGFbYJY2iFvRbIuKuYvJaSeOL9vHAuqGWjYj5ETEQEQOjGN2Jms2sBU3DLknA9cCKiPh2XdNCYHbxejZwT+fLM7NOGc5XXGcC5wJPSlpaTLsMmAfcIel84CXgzO6UaM2M/e1XWl524TvHlLZvfW19y+u2/tI07BHxMNDoQu4JnS3HzLrFd9CZJeGwmyXhsJsl4bCbJeGwmyXhsJsl4X8lvQvQ6PI7D2dNeLzldb++ad/S9tjoW5x3F96ymyXhsJsl4bCbJeGwmyXhsJsl4bCbJeGwmyXh6+y7gq1bS5vnrzi2YdtFn1tZuuyDLx9Z2j6R5aXttuvwlt0sCYfdLAmH3SwJh90sCYfdLAmH3SwJh90sCV9n3wXElvKBkSdf+l7Dtql/d27pslq6X0s12a7HW3azJBx2syQcdrMkHHazJBx2syQcdrMkHHazJJpeZ5c0CbgJOBjYBsyPiCslzQX+BHitmPWyiLi3W4VaY1uffaFh26Fn9rAQ62vDualmC3BxRDwmaT9giaT7i7bvRMQ/dK88M+uUpmGPiDXAmuL1BkkrgIndLszMOmunjtklTQaOARYXky6U9ISkGyQd0GCZOZIGJQ1uxkMJmVVl2GGXtC9wJ3BRRLwDXAMcAUyjtuW/YqjlImJ+RAxExMAoyscsM7PuGVbYJY2iFvRbIuIugIhYGxFbI2IbcC0wo3tlmlm7moZdkoDrgRUR8e266ePrZvsisKzz5ZlZpwznbPxM4FzgSUlLi2mXAedImgYEsBL4SlcqNLOOGM7Z+IcBDdHka+pmuxDfQWeWhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloTDbpaEw26WhMNuloQionedSa8BL9ZNOhBY37MCdk6/1tavdYFra1UnazssIg4aqqGnYf9I59JgRAxUVkCJfq2tX+sC19aqXtXm3XizJBx2sySqDvv8ivsv06+19Wtd4Npa1ZPaKj1mN7PeqXrLbmY94rCbJVFJ2CWdIunnkp6VdGkVNTQiaaWkJyUtlTRYcS03SFonaVndtDGS7pf0TPE85Bh7FdU2V9IrxWe3VNJpFdU2SdJPJK2QtFzSXxTTK/3sSurqyefW82N2SSOBp4ETgVXAo8A5EfFUTwtpQNJKYCAiKr8BQ9JvAu8CN0XE0cW0vwfeiIh5xR/KAyLikj6pbS7wbtXDeBejFY2vH2YcOB34MhV+diV1nUUPPrcqtuwzgGcj4vmI2ATcDsyqoI6+FxEPAW98aPIsYEHxegG1X5aea1BbX4iINRHxWPF6A7B9mPFKP7uSunqiirBPBF6ue7+K/hrvPYD7JC2RNKfqYoYwLiLWQO2XBxhbcT0f1nQY71760DDjffPZtTL8ebuqCPtQQ0n10/W/mRHxGeBU4IJid9WGZ1jDePfKEMOM94VWhz9vVxVhXwVMqnt/CLC6gjqGFBGri+d1wN3031DUa7ePoFs8r6u4nl/qp2G8hxpmnD747Koc/ryKsD8KTJF0uKQ9gbOBhRXU8RGS9ilOnCBpH+Ak+m8o6oXA7OL1bOCeCmvZQb8M491omHEq/uwqH/48Inr+AE6jdkb+OeCvq6ihQV2fBB4vHsurrg24jdpu3WZqe0TnA58AFgHPFM9j+qi2fwaeBJ6gFqzxFdV2LLVDwyeApcXjtKo/u5K6evK5+XZZsyR8B51ZEg67WRIOu1kSDrtZEg67WRIOu1kSDrtZEv8HFlTnzSmXpYIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output :  1\n"
     ]
    }
   ],
   "source": [
    "plt.title(\"Actual Image\")\n",
    "plt.imshow(test_images[5], interpolation='nearest')\n",
    "plt.show()\n",
    "print(\"Predicted output : \",list(pred[5]).index(1))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
